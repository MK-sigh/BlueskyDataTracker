import streamlit as st
import requests
import pandas as pd
import os
from dotenv import load_dotenv

# --- è¨­å®š ---
SPRINGBOOT_POST = "http://localhost:8080/api/v1/collector/run"
SPRINGBOOT_GET = "http://localhost:8080/api/v1/collector/search"
# DBæ¥ç¶šæƒ…å ±
# .envãƒ•ã‚¡ã‚¤ãƒ«ã‚’èª­ã¿è¾¼ã‚€
load_dotenv()

# ç’°å¢ƒå¤‰æ•°ã‚’å–å¾—ã™ã‚‹
db_url = os.getenv("DATABASE_URL")
db_user = os.getenv("DATABASE_USER")
db_pass = os.getenv("DATABASE_PASSWORD")

# å½¢å¼: postgresql://ãƒ¦ãƒ¼ã‚¶ãƒ¼å:ãƒ‘ã‚¹ãƒ¯ãƒ¼ãƒ‰@ãƒ›ã‚¹ãƒˆå:ãƒãƒ¼ãƒˆç•ªå·/ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹å
DB_URL = db_url.replace("jdbc:", "").replace("://", f"://{db_user}:{db_pass}@")

st.set_page_config(page_title="Bluesky Data Tracker", layout="wide")
st.title("ğŸ¦‹ Bluesky  Data Tracker")

# --- ã‚µã‚¤ãƒ‰ãƒãƒ¼ï¼šãƒ‡ãƒ¼ã‚¿åé›†å‘½ä»¤ ---
st.sidebar.header("ãƒ‡ãƒ¼ã‚¿åé›†")
query = st.sidebar.text_input("æ¤œç´¢ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰", value="Python")
if st.sidebar.button("Spring Bootã§åé›†é–‹å§‹"):
    with st.spinner("åé›†ã—ã¦ã„ã¾ã™..."):
        try:
            # 1. åé›†å®Ÿè¡Œ
            response = requests.post(SPRINGBOOT_POST, params={"q": query})
            # 2. Javaã®æ¤œç´¢APIã‹ã‚‰ã€Œãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°æ¸ˆã¿ãƒ‡ãƒ¼ã‚¿ã€ã‚’å–å¾—
            search_res = requests.get(SPRINGBOOT_GET, params={"q": query})
            # st.write("GETãƒ¬ã‚¹ãƒãƒ³ã‚¹:", search_res.text)
            if search_res.status_code == 200:
                # JSONã‚’ç›´æ¥DataFrameã«å¤‰æ›ï¼
                st.session_state.posts_df = pd.DataFrame(search_res.json())
                st.sidebar.success(f"{len(st.session_state.posts_df)}ä»¶ã®ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—ã—ã¾ã—ãŸ")
            else:
                st.sidebar.error("å–å¾—å¤±æ•—")
        except Exception as e:
            st.sidebar.error(f"ã‚¨ãƒ©ãƒ¼: {e}")



# --- ãƒ¡ã‚¤ãƒ³ç”»é¢ï¼šãƒ‡ãƒ¼ã‚¿å¯è¦–åŒ– ---
st.header("ğŸ“Š ãƒ‡ãƒ¼ã‚¿åˆ†æ")
# ã‚»ãƒƒã‚·ãƒ§ãƒ³çŠ¶æ…‹ã®åˆæœŸåŒ–
if "posts_df" not in st.session_state:
    st.session_state.posts_df = pd.DataFrame()

raw_posts = st.session_state.posts_df

if not raw_posts.empty:

    # éšå±¤æ§‹é€ ï¼ˆauthor.handleç­‰ï¼‰ã‚’å¹³ã‚‰ãªåˆ—ã«å¤‰æ›ã™ã‚‹
    # ã“ã‚Œã«ã‚ˆã‚Š 'author_handle' ã‚„ 'author_displayName' ã¨ã„ã†åˆ—ãŒç”Ÿã¾ã‚Œã¾ã™
    df_posts = pd.json_normalize(raw_posts.to_dict('records'), sep='_')
    
    # åˆ—åã®ç¢ºèªï¼ˆãƒ‡ãƒãƒƒã‚°ç”¨ï¼šå¾Œã§æ¶ˆã—ã¦OKï¼‰
    # st.write("ãƒ‡ãƒãƒƒã‚°åˆ—å:", df_posts.columns.tolist())
    # 0:"id"
    # 1:"uri"
    # 2:"cid"
    # 3:"text"
    # 4:"createdAt"
    # 5:"indexedAt"
    # 6:"language"
    # 7:"bookmarkCount"
    # 8:"replyCount"
    # 9:"repostCount"
    # 10:"likeCount"
    # 11:"quoteCount"
    # 12:"authorId"
    # 13:"author_id"
    # 14:"author_did"
    # 15:"author_handle"
    # 16:"author_displayName"
    # 17:"author_createdAccountAt"

    st.write(f"ç¾åœ¨ã®è¡¨ç¤ºä»¶æ•°: {len(df_posts)} ä»¶")
    
    # æ™‚ç³»åˆ—ã‚°ãƒ©ãƒ•ã®å‡¦ç†
    # Javaã‹ã‚‰æ¥ã‚‹æ™‚é–“ã¯æ–‡å­—åˆ—ãªã®ã§å¤‰æ›ãŒå¿…è¦
    df_posts['createdAt'] = pd.to_datetime(
        df_posts['createdAt'], format='ISO8601', utc=True)

    st.subheader("æœ€æ–°ã®æŠ•ç¨¿ãƒ‡ãƒ¼ã‚¿")
    # APIã‹ã‚‰å±Šã„ãŸå…¨ãƒ‡ãƒ¼ã‚¿ã‹ã‚‰ã€å¿…è¦ãªåˆ—ã ã‘ã‚’æŠ½å‡º
    display_df = df_posts[["author_handle", "author_displayName", "text", "createdAt"]]
    st.dataframe(display_df)

    st.subheader("æŠ•ç¨¿æ•°ã®æ¨ç§»")
    time_series = df_posts.set_index('createdAt').resample('H').size()
    st.line_chart(time_series)

# --- ã‚¿ã‚°ã®é›†è¨ˆå‡¦ç† ---
# 0:"postId"
# 1:"tagId"
# 2:"Tag.id"
# 3:"Tag.tag"

    # --- ã‚¿ã‚°ã®é›†è¨ˆå‡¦ç† ---
    st.subheader("ğŸ·ï¸ æŠ•ç¨¿ã‚¿ã‚° TOP 10")
    # df_posts ãŒç©ºã§ãªãã€ã‹ã¤ 'tags' åˆ—ãŒå­˜åœ¨ã™ã‚‹ã‹ãƒã‚§ãƒƒã‚¯
    if not df_posts.empty and 'tags' in df_posts.columns:
        try:
            # 1. 'tags' åˆ—ã«ã¯ãƒªã‚¹ãƒˆãŒå…¥ã£ã¦ã„ã‚‹ã®ã§ã€ãã‚Œã‚’å±•é–‹ã—ã¦1è¡Œãšã¤ã«ã™ã‚‹
            # ã“ã‚Œã«ã‚ˆã‚Šã€1ã¤ã®æŠ•ç¨¿ã«3ã¤ã‚¿ã‚°ãŒã‚ã‚Œã°ã€3è¡Œã«å¢—ãˆã¾ã™
            df_exploded = df_posts.explode('tags')
            
            # 2. å±•é–‹ã•ã‚ŒãŸä¸­èº«ï¼ˆè¾æ›¸ï¼‰ã‚’ã•ã‚‰ã«è¡¨å½¢å¼ã«å±•é–‹ã™ã‚‹
            # ã“ã“ã§è¾æ›¸ã®ä¸­ã® 'tag_tag' (Tagã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆå†…ã®tagæ–‡å­—åˆ—) ã‚’å–ã‚Šå‡ºã™
            tags_normalized = pd.json_normalize(df_exploded['tags'].dropna())
            
            if not tags_normalized.empty:
                # Javaã® PostTag.java ã§ private Tag Tag; ã¨ã—ã¦ã„ã‚‹å ´åˆã€
                # ã‚«ãƒ©ãƒ åã¯ 'tag_tag' ã«ãªã£ã¦ã„ã‚‹å¯èƒ½æ€§ãŒé«˜ã„ã§ã™
                # ã‚‚ã—å‹•ã‹ãªã‘ã‚Œã°ã€st.write(tags_normalized.columns.tolist()) ã§ç¢ºèª
                tag_col = 'Tag.tag' 
                
                if tag_col in tags_normalized.columns:
                    tag_counts = tags_normalized[tag_col].value_counts().reset_index()
                    tag_counts.columns = ['ã‚¿ã‚°', 'æŠ•ç¨¿æ•°']
                    
                    col1, col2 = st.columns([2, 1])
                    with col1:
                        st.bar_chart(tag_counts.set_index('ã‚¿ã‚°').head(10))
                    with col2:
                        st.dataframe(tag_counts.head(10), hide_index=True)
                else:
                    st.info("ã‚¿ã‚°åãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚")
            else:
                st.info("ã‚¿ã‚°ãŒä»˜ã„ã¦ã„ã‚‹æŠ•ç¨¿ã¯ã‚ã‚Šã¾ã›ã‚“ã€‚")
                
        except Exception as e:
            st.error(f"é›†è¨ˆã‚¨ãƒ©ãƒ¼: {e}")
    else:
        st.info("è¡¨ç¤ºã§ãã‚‹ã‚¿ã‚°æƒ…å ±ãŒã‚ã‚Šã¾ã›ã‚“ã€‚")